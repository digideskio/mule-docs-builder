[[CloudHubFabric-CloudHubFabric Enterprise]]
= CloudHub Fabric  +
_Enterprise_

CloudHub Fabric provides scalability, workload distribution, and added
reliability to CloudHub applications. These capabilities are powered by
CloudHub's scalable load-balancing
service, **link:#CloudHubFabric-WorkerScaleout[worker scaleout]**, and
*link:#CloudHubFabric-PersistentQueues[persistent queueing]* features.

You can link:#CloudHubFabric-EnablingCloudHubFabricFeatures[activate
these features] on a per-application basis using the CloudHub console
when you deploy a new application or redeploy an existing application.

 Contents
link:#CloudHubFabric-Assumptions[Assumptions]
link:#CloudHubFabric-WorkerScaleout[Worker Scaleout]
link:#CloudHubFabric-PersistentQueues[Persistent Queues]
link:#CloudHubFabric-EnablingCloudHubFabricFeatures[Enabling CloudHub
Fabric Features]
link:#CloudHubFabric-UseCases[Use Cases]
link:#CloudHubFabric-BuildingMuleApplicationstoSupportPersistentQueues[Building
Mule Applications to Support Persistent Queues]
*
link:#CloudHubFabric-DifferencesbetweenOn-PremisesVMQueuesandCloudHubVMQueues[Differences
between On-Premises VM Queues and CloudHub VM Queues]

link:#CloudHubFabric-GoFurther[Go Further]
 

[[CloudHubFabric-Assumptions]]
== Assumptions

CloudHub Fabric requires a CloudHub Enterprise or Partner account
type. This document assumes that you have
a http://www.mulesoft.com/cloudhub-plans-pricing[one of those account
types] and that you are familiar
with link:/documentation/display/current/Deploying+a+CloudHub+Application[deploying
applications using the CloudHub console]. 

 

[[CloudHubFabric-WorkerScaleout]]
== Worker Scaleout

CloudHub allows you to assign multiple workers to an application,
providing horizontal scalability. This fine-grained control over worker
provisioning gives you the flexibility to scale up your application to
handle higher loads (or scale down during low-load periods) at any time.

[cols=",",]
|=======================================================================
|image:/documentation/images/icons/emoticons/check.png[image] |For specs
and details about each of the worker sizes see the *Worker Sizing*
section of
link:/documentation/display/current/Deploying+a+CloudHub+Application[Deploying
a CloudHub Application]
|=======================================================================

 

To allocate workers, select options from the drop down menus to
configure the computing power that you need. 

image:/documentation/download/attachments/118981817/image2014-10-25+0%3A0%3A22.png?version=1&modificationDate=1414220423256[image]
Each application can deploy up to four workers of any type. However, you
may be limited to fewer than four workers based on how many workers are
available in your subscription.
See link:/documentation/display/current/Deploying+a+CloudHub+Application#DeployingaCloudHubApplication-WorkerSizing[Worker
Sizing] for more information about deploying to multiple workers.

Worker scaleout also adds additional reliability. MuleSoft will
automatically distribute multiple workers for the same application
across two or more datacenters for maximum reliability.

When deploying your application to two or more workers, you can
distribute workloads across these instances of Mule. CloudHub provides
two facilities to do this:

1.  The HTTP load balancing service will automatically distribute HTTP
requests among your assigned workers.
2.  Persistent message queues (see below)

[cols=",",]
|=======================================================================
|image:/documentation/images/icons/emoticons/warning.png[image]
|link:/documentation/display/current/Batch+Processing[Batch jobs] only
run on a single worker at a time, and will not be distributed across
multiple workers.
|=======================================================================

 +
 +

[[CloudHubFabric-PersistentQueues]]
== Persistent Queues

Persistent queues ensure zero message loss and allows you to distribute
workloads across a set of workers.** **

1.  * If your application is deployed to more than one worker,
persistent queues allow interworker communication and workload
distribution. For example, if a large file is placed in the queue, your
workers can divide it up and process it in parallel. 
* Persistent queues will guarantee delivery of your messages, even if
one or more workers or datacenters go down, providing additional message
security for high-stakes processing. 
* With persistent queues enabled on your application, you have runtime
visibility into your queues on the
link:/documentation/display/current/Managing+Queues[Queues tab] in the
CloudHub console. +
 +

[cols=",",]
|=======================================================================
|image:/documentation/images/icons/emoticons/warning.png[image] |Note
that persistent queues do not guarantee one-time-only message delivery.
Duplicate messages may be sent. If one-time-only message delivery is
critical for your use case, do not enable persistent queues.
|=======================================================================

To learn more about how to work with persistent queues in your
application, see
link:/documentation/display/current/Managing+Queues[Managing Queues].

 

[[CloudHubFabric-EnablingCloudHubFabricFeatures]]
== Enabling CloudHub Fabric Features

You can enable and disable either or both features of CloudHub Fabric in
one of two ways:

* when deploying an application to CloudHub for the first time using the
CloudHub console
* by accessing the *Deployment* tab in the CloudHub console for a
previously-deployed application

Next to **Workers**, select options from the drop-down menus to define
the number and type of workers assigned to your application. See
link:/documentation/display/current/Deploying+a+CloudHub+Application#DeployingaCloudHubApplication-WorkerSizing[Worker
Sizing] for more information about deploying to multiple workers.

Expand the *Advanced* section, then check the **Persistent
Queues** checkbox to enable queue persistence. 

image:/documentation/download/attachments/118981817/image2014-10-25+0%3A3%3A10.png?version=1&modificationDate=1414220590942[image]

If your application is already deployed, you need to redeploy it in
order for your new settings to take effect. 

 

[[CloudHubFabric-UseCases]]
== Use Cases

Depending on your use case, you may wish to take advantage of both
CloudHub Fabric features on the same application, or you may prefer to
enable just one of them, or neither.

Considerations:

* In order to take advantage of persistent queueing, you must first set
up your Mule application to support this feature. See
link:#CloudHubFabric-BuildingMuleApplicationstoSupportPersistentQueues[Building
Mule Applications to Support Persistent Queues], below, for more
information.
* Enabling persistent queues has a performance implication: Putting a
small message (50kb or less) on a queue can take 10-20 milliseconds
(ms); taking the same message off a queue can take 70-100ms. 
* Adding additional workers increases the cost of service.   +
 +

Use Case
Suggested CloudHub Fabric Configuration
Implications
You want to scale out your application, but you are satisfied with the
existing highly available CloudHub architecture in terms of preventing
service interruption or message loss.
Persistent Queues Enabled? *No*

Number of Workers: *2 or more*

 

* Application performance is not affected by queueing latency.
* No need to configure your application to support queue persistence.
* If one datacenter experiences an outage, your workers are available in
a different data center.

 

You have a high-stakes process for which you need to protect against
message loss, but you are not experiencing issues with handling
processing load and are OK with some service interruption in the case of
a data center outage.
Persistent Queues Enabled? *Yes*

Number of Workers: *1*

* Application may experience some queueing latency.
* You need to configure your application to support queue persistence
before deploying.
* If the datacenter in which your worker operates experiences an outage,
CloudHub will automatically migrate your application to another
availability zone. You may experience some downtime during the
migration; however, your persistent queue will ensure zero message loss.

You have a high-stakes process for which you need to protect against
message loss, avoid any chance of service interruption, and handle large
processing loads.
Persistent Queues Enabled? *Yes*

Number of Workers: *2 or more*

* Application may experience some queueing latency.
* You need to configure your application to support queue persistence
before deploying.
* If one datacenter experiences an outage, your workers are
automatically distributed to ensure redundancy.

You have an application that does not have any special requirements
regarding either processing load or message loss.
Persistent Queues Enabled? *No*

Number of Workers: *1*

* Application performance is not affected by queueing latency.
* No need to configure your application to support queue persistence.
* If the datacenter in which your worker operates experiences an outage,
CloudHub will automatically migrate your application to another
availability zone, but you may experience some downtime and message loss
during the migration.

[cols=",",]
|=======================================================================
|image:/documentation/images/icons/emoticons/information.png[image] a|
*Persistent Queuing Behavior for Applications Containing Batch Jobs* +
When you deploy an application containing
link:/documentation/display/current/Batch+Processing[batch jobs] to
CloudHub with persistent queues enabled, the batch jobs will use
CloudHub's persistent queuing feature for the batch queuing
functionality to ensure zero message loss. However, there are two
limitations:

* Batch jobs using CloudHub persistent queues experience additional
latency
* CloudHub persistent queues will occasionally process a message more
than once. If your use case requires that each message be guaranteed to
be processed only once, consider deploying the application without
enabling persistent queues.

|=======================================================================

 

[[CloudHubFabric-BuildingMuleApplicationstoSupportPersistentQueues]]
== Building Mule Applications to Support Persistent Queues

In order for your application to reap the benefits of persistent
queuing, you will need to implement
link:/documentation/display/current/Reliability+Patterns[reliability
patterns] in your application code, separating individual
link:/documentation/display/current/XA+Transactions[XA transactions]
with link:/documentation/display/current/VM+Transport+Reference[VM
transports], as shown below. 

image:/documentation/download/attachments/118981817/CH_Fabric.png?version=1&modificationDate=1414198598674[image]

The **reliable acquisition flow** delivers a message reliably from the
inbound endpoint of your application to an outbound VM endpoint. If the
reliable acquisition flow cannot put the message into the VM queue, it
ensures that the message is not lost by returning an "unsuccessful
request" response to the client so that the client can retry the
request.

The **application logic flow** delivers the message from an inbound VM
endpoint to the business logic processing in your application. This flow
represents one transaction. (Your business logic may involve several
other transactions, not shown.) 

In between these two flows, a *persistent VM queue* holds the messages
committed by the reliable acquisition flow until they are ready for
processing by the application logic flow. In case of a processing error
within the transaction or in case of a transaction timeout (the time
allotted for the transaction is exceeded), Mule triggers a rollback.
This rollback erases any partial processing that has occurred on the
message and places the message back on the queue. If your Mule instance
experiences an outage and is unable to explicitly roll back a
transaction, the transaction will automatically roll back once the time
allotted for the transaction is exceeded. The allotted time is
determined by the `timeout` attribute of the transaction element. You
can configure the timeout yourself, or accept the default.

It is helpful to think of each transaction in terms of three steps:

1.  **Begin**. Mule kicks off the processing of all subcomponents within
the transaction. 
2.  **Commit**. Mule sends the result of the completed transaction on to
the next step. (For XA transactions, the commit step has two phases: a
_commit-request phase_ and a __commit phase__. During the commit-request
phase, Mule coordinates the results of the multiple resources within the
scope of the transaction and confirms that all processing executed
successfully and is ready to commit. The commit phase then calls each
resource to commit its processing.)
3.  **Rollback**. If an error occurs in either the Begin or Commit
steps, Mule rolls back the operations within the transaction so that no
one part results in partial completion.

The following code snippet provides an example of an application set up
in a reliability pattern using VM transports for queue persistence on
CloudHub.

[[CloudHubFabric-DifferencesbetweenOn-PremisesVMQueuesandCloudHubVMQueues]]
=== Differences between On-Premises VM Queues and CloudHub VM Queues

Although you can refer to the complete references for
link:/documentation/display/current/Transaction+Management[Transaction
Management], the
link:/documentation/display/current/VM+Transport+Reference[VM
transport], and
link:/documentation/display/current/Reliability+Patterns[Reliability
Patterns], note that CloudHub imposes some key differences in the way
that persistent queues are implemented. 

VM Queues in On-Premises Applications
VM Queues in CloudHub Applications
You can configure the maximum number of outstanding messages using the
queue-profile element.
There is no limit to the number of outstanding messages in CloudHub.
Even if you have a queue-profile element coded in your application with
a maximum number of outstanding messages, CloudHub allows unlimited
outstanding messages if you deploy the application to CloudHub with the
Persistent Queues checkbox checked.
You can toggle the persistence of the queue using the queue-profile
element.
The persistence of your queue is managed using the Persistent Queues
checkbox in the Advanced Details section of the deployment dialog. Even
if you have a queue-profile element coded in your application, CloudHub
overrides these settings when you deploy the application to CloudHub
with the Persistent Queues checkbox checked.
You can define a queue store for your VM queue to use.
CloudHub manages the queue store for you, so there is no need to define
a queue store.
Transaction commits and rollbacks for XA transactions operate according
to the http://en.wikipedia.org/wiki/Two-phase_commit_protocol[two-phase
commit algorithm].
In CloudHub, there is an important exception to the way the two-phase
commit algorithm works for XA transactions when a message is being added
to a queue. See the link:#CloudHubFabric-knownissue[known issue]
described below for details. (Note that when CloudHub _consumes_
messages from a persistent queue, this exception to the two-phase commit
algorithm does not apply.)

[cols=",",]
|=======================================================================
|image:/documentation/images/icons/emoticons/warning.png[image] a|
*Known Issue* +
When messages are added to a VM queue in CloudHub, the two-phase commit
protocol for XA transactions can fail to roll back a complete
transaction if the following conditions are true:

* The commit-request phase has completed successfully. (All
participating processes within the transaction execute successfully, so
the message is ready to commit to the queue.)
* During the commit phase, an error occurs that causes a subprocess
within the transaction to fail to commit, triggering a rollback of the
transaction.
* The VM outbound endpoint completes its commit before the rollback
occurs.

If all three above conditions are true, the message will be added to the
queue instead of being rolled back as intended by the transaction
rollback process. No message loss occurs, and the transaction can still
be repeated, but the outbound VM queue will contain an unintended
message.

Note that this issue occurs only when a flow _produces_ messages that
need to be added to a VM queue. There is no effect on the process of
consuming messages from queues.

|=======================================================================

 

[[CloudHubFabric-GoFurther]]
== Go Further

*
See link:/documentation/display/current/Deploying+a+CloudHub+Application#DeployingaCloudHubApplication-WorkerSizing[Worker
Sizing] for more information about deploying to multiple workers.
* See link:/documentation/display/current/Managing+Queues[Managing
Queues] for more information about viewing your queues at runtime.
* Learn more about the
link:/documentation/display/current/CloudHub+Architecture[CloudHub
architecture].
* Investigate the other
link:/documentation/display/current/Deploying+a+CloudHub+Application#DeployingaCloudHubApplication-AdvancedApplicationOptions[advanced
options for deploying your CloudHub applications].
* Refer to the complete references
for link:/documentation/display/current/Transaction+Management[Transaction
Management],
the link:/documentation/display/current/VM+Transport+Reference[VM
transport],
and link:/documentation/display/current/Reliability+Patterns[Reliability
Patterns].

